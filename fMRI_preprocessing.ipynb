{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI PREPROCESSING \n",
    "\n",
    "This pipeline is adapted from the example_preprocessing module in the nipype tutorial https://miykael.github.io/nipype_tutorial/notebooks/example_preprocessing.html\n",
    "\n",
    "**step implemented**\n",
    "\n",
    "1. slice time correction (fsl)\n",
    "2. motion correction (fsl)\n",
    "3. artifact detection to identify outliers (fsl)\n",
    "4. segmentation - fsl FAST\n",
    "5. coregistration with anatomical (fls)\n",
    "6. smoothing (fsl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import nibabel as nb\n",
    "from nipype import Node,Workflow\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nilearn.plotting import plot_anat\n",
    "from os.path import join as opj\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "from nipype.interfaces.spm import Normalize12, NewSegment\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from bids.layout import BIDSLayout\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.fsl import (BET,ExtractROI,FAST,FLIRT,MCFLIRT,ImageMaths,SliceTimer,Threshold,Smooth)\n",
    "\n",
    "\n",
    "#tpm_img ='/home/ubuntu/Documents/MATLAB/spm12/tpm/TPM.nii'\n",
    "#\n",
    "#tissue1 = ((tpm_img, 1), 1, (True,False), (False, False))\n",
    "#tissue2 = ((tpm_img, 2), 1, (True,False), (False, False))\n",
    "#tissue3 = ((tpm_img, 3), 2, (True,False), (False, False))\n",
    "#tissue4 = ((tpm_img, 4), 3, (False,False), (False, False))\n",
    "#tissue5 = ((tpm_img, 5), 4, (False,False), (False, False))\n",
    "#tissue6 = ((tpm_img, 6), 2, (False,False), (False, False))\n",
    "#\n",
    "#tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/home/ubuntu/Documents/BIDs/XP2'\n",
    "experiment_dir='/home/ubuntu/Documents/windowshare/output/XP2'\n",
    "output_dir='datasink'\n",
    "working_dir='workingdir'\n",
    "\n",
    "subject_list_2d=['xp204','xp205','xp207','xp210','xp212','xp213','xp215','xp216','xp217','xp221','xp223']\n",
    "subject_list=['xp201','xp202','xp203','xp206','xp208','xp209','xp211','xp214','xp218','xp219','xp220','xp222']\n",
    "\n",
    "task_list=['1dNF']\n",
    "run_list=['01','02']\n",
    "fwhm_list=[6]\n",
    "\n",
    "#isometric voxel resolution\n",
    "desired_voxel_iso = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata info from BIDs layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND INFO FROM BIDS LAYOUT\n",
    "func_file='/home/ubuntu/Documents/BIDs/XP2/sub-xp201/func/sub-xp201_task-1dNF_run-01_bold.nii.gz'\n",
    "layout_data=BIDSLayout(data_dir)\n",
    "sub_list=layout_data.get_subjects()\n",
    "layout_data.get_tasks()\n",
    "TR=layout_data.get_metadata(func_file)[\"RepetitionTime\"]\n",
    "sliceTiming=layout_data.get_metadata(func_file)[\"SliceTiming\"]\n",
    "slice_order=[sliceTiming.index(x) for x in sorted(sliceTiming)]\n",
    "\n",
    "print(\"TR: \"+str(TR))\n",
    "print(str(slice_order))\n",
    "print(\"image dim: \"+ str(layout_data.get_metadata(func_file)[\"PhaseEncodingSteps\"])+ \" X \"+ str(layout_data.get_metadata(func_file)[\"PhaseEncodingSteps\"])+ \" X \" + str(len(sliceTiming)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLICE TIME CORRECTION\n",
    "slicetimer = Node(SliceTimer(index_dir=False,\n",
    "                             interleaved=True,\n",
    "                             output_type='NIFTI',\n",
    "                             time_repetition=TR),\n",
    "                  name=\"slicetimer\")\n",
    "\n",
    "#MOTION CORRECTION\n",
    "mcflirt=Node(MCFLIRT(mean_vol=True,\n",
    "                    save_plots=True,\n",
    "                     output_type='NIFTI'),\n",
    "             name=\"mcflirt\")\n",
    "\n",
    "#ARTIFACT DETECTION\n",
    "art=Node(ArtifactDetect(norm_threshold=2,\n",
    "                       zintensity_threshold=2,\n",
    "                       mask_type='spm_global',\n",
    "                       parameter_source='FSL',\n",
    "                       use_differences=[True,False],\n",
    "                       plot_type='svg'), name='art')\n",
    "\n",
    "\n",
    "#COREGISTRATION FUNC-ANAT IMAGEs\n",
    "coreg = Node(FLIRT(dof=6,\n",
    "                   cost='bbr',\n",
    "                   schedule='/usr/local/fsl/etc/flirtsch/bbr.sch',\n",
    "                   output_type='NIFTI'),\n",
    "             name=\"coreg\")\n",
    "\n",
    "#SMOOTH\n",
    "\n",
    "smooth = Node(Smooth(), name=\"smooth\")\n",
    "smooth.iterables = (\"fwhm\", fwhm_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coregistration workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BET -Skullstrip anatomical Image\n",
    "bet_anat=Node(BET(frac=0.4,\n",
    "                 robust=True,\n",
    "                 output_type='NIFTI_GZ'),\n",
    "             name=\"bet_anat\")\n",
    "#SEGMENTATION\n",
    "\n",
    "# with FAST \n",
    "segmentation=Node(FAST(output_type='NIFTI_GZ'),name=\"segmentation\")\n",
    "\n",
    "#with SPM\n",
    "#segmentation = Node(NewSegment(tissues=tissues), name='segmentation')\n",
    "\n",
    "\n",
    "# Select WM segmentation file from segmentation output\n",
    "# for fast\n",
    "def get_wm(files):\n",
    "    return files[-1]\n",
    "\n",
    "#for spm\n",
    "#def get_wm(files):\n",
    " #   return files[1][0]\n",
    "\n",
    "#Threshold white matter probablity map \n",
    "threshold_WM = Node(Threshold(thresh=0.5,\n",
    "                              args='-bin',\n",
    "                              output_type='NIFTI'),\n",
    "                name=\"threshold_WM\")\n",
    "\n",
    "#FLIRT - pre-alignement (6 DOF) of functional to anatomical image\n",
    "coreg_pre=Node(FLIRT(dof=6, output_type='NIFTI_GZ'),name=\"coreg_pre\")\n",
    "\n",
    "#FLIRT - coregistration of functional to anatomical with BBR\n",
    "coreg_bbr=Node(FLIRT(dof=6,cost='bbr',\n",
    "                    schedule=opj(os.getenv('FSLDIR'),'etc/flirtsch/bbr.sch'),\n",
    "                    output_type='NIFTI_GZ'), name='coreg_bbr')\n",
    "\n",
    "#APPLY coregistration warp to functional image\n",
    "applywarp = Node(FLIRT(interp='spline',\n",
    "                       apply_isoxfm=desired_voxel_iso,\n",
    "                       output_type='NIFTI'),\n",
    "                 name=\"applywarp\")\n",
    "\n",
    "#apply coregistration warp to mean file\n",
    "applywarp_mean=Node(FLIRT(interp='spline',\n",
    "                         apply_isoxfm=desired_voxel_iso,\n",
    "                         output_type='NIFTI_GZ'),\n",
    "                 name=\"applywarp_mean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a coregistration workflow and connect nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregwf=Workflow(name='coregwf')\n",
    "coregwf.base_dir=opj(experiment_dir,working_dir)\n",
    "\n",
    "\n",
    "coregwf.connect([\n",
    "              #(bet_anat,segmentation,[('out_file','channel_files')]),\n",
    "               (bet_anat,segmentation,[('out_file','in_files')]),\n",
    "               (segmentation, threshold_WM, [(('partial_volume_files', get_wm),\n",
    "                                          'in_file')]),\n",
    "               #  (segmentation, threshold_WM, [(('native_class_images', get_wm),\n",
    "               #                          'in_file')]),\n",
    "                (bet_anat,coreg_pre,[('out_file','reference')]),\n",
    "                (threshold_WM,coreg_bbr,[('out_file','wm_seg')]),\n",
    "                (coreg_pre,coreg_bbr,[('out_matrix_file','in_matrix_file')]),\n",
    "                (coreg_bbr,applywarp,[('out_matrix_file','in_matrix_file')]),\n",
    "                (bet_anat,applywarp,[('out_file','reference')]),\n",
    "                (coreg_bbr,applywarp_mean,[('out_matrix_file','in_matrix_file')]),\n",
    "                (bet_anat,applywarp_mean,[('out_file','reference')]),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inforsource- to iterate over list of subject names\n",
    "# zrun_id because I want it to be at the end of the folder tree (apparently IdentityInterface follows alphabetic order)\n",
    "infosource=Node(IdentityInterface(fields=['subject_id','task_id','zrun_id']), \n",
    "               name=\"infosource\")\n",
    "infosource.iterables=[('subject_id',subject_list),\n",
    "                     ('task_id',task_list),\n",
    "                     ('zrun_id',run_list)]\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-{subject_id}/anat/'\n",
    "                     'sub-{subject_id}_T1w.nii.gz',\n",
    "             'func': 'sub-{subject_id}/func/'\n",
    "                     'sub-{subject_id}_task-{task_id}_run-{zrun_id}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                      base_directory=data_dir,\n",
    "                      sort_filelist=True),\n",
    "          name='selectfiles')\n",
    "\n",
    "\n",
    "# DataSink- creates output folder for important outputs\n",
    "datasink=Node(DataSink(base_directory=experiment_dir,\n",
    "                      container=output_dir), name=\"datasink\")\n",
    "\n",
    "substitutions=[('_task_id_','/task-'),\n",
    "               ('_subject_id_','sub-'),\n",
    "              ('_zrun_id_','/run-'),\n",
    "              ('_fwhm_','fwhm-'),\n",
    "              ('_roi',''),\n",
    "              ('_mcf',''),\n",
    "              ('_st',''),\n",
    "              ('_flirt',''),\n",
    "              ('_smooth',''),\n",
    "              ('.nii_mean_reg','_mean'),\n",
    "              ('.nii.par','.par')]\n",
    "\n",
    "subjFolders=[('fwhm-%s/' % f, 'fwhm-%s-' % f) for f in fwhm_list]\n",
    "substitutions.extend(subjFolders)\n",
    "datasink.inputs.substitutions=substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc=Workflow(name='preprocessing',base_dir=opj(experiment_dir,working_dir))\n",
    "\n",
    "preproc.connect([(infosource,selectfiles,[('subject_id','subject_id'),\n",
    "                                          ('task_id','task_id'),\n",
    "                                          ('zrun_id','zrun_id')]),\n",
    "                (selectfiles,mcflirt,[('func','in_file')]),\n",
    "                (mcflirt,slicetimer,[('out_file','in_file')]),\n",
    "                (selectfiles,coregwf,[('anat','bet_anat.in_file'),\n",
    "                                     ('anat','coreg_bbr.reference')]),\n",
    "                (mcflirt,coregwf,[('mean_img','coreg_pre.in_file'),\n",
    "                                 ('mean_img','coreg_bbr.in_file'),\n",
    "                                 ('mean_img','applywarp_mean.in_file')]),\n",
    "                (slicetimer,coregwf,[('slice_time_corrected_file','applywarp.in_file')]),\n",
    "                (coregwf,smooth,[('applywarp.out_file','in_file')]),\n",
    "               # (coregwf,normalize,[('applywarp.out_file','image_to_align')]),\n",
    "               #(normalize,smooth,[('normalized_image','in_file')]),\n",
    "                 \n",
    "                (mcflirt,datasink,[('par_file','preproc.@par')]),\n",
    "                (smooth,datasink,[('smoothed_file','preproc.@smooth')]),\n",
    "               # (normalize,datasink,[('normalized_files','norm_spm.@files'),\n",
    "                        #            ('normalized_image','norm_spm.@image')]),\n",
    "                (coregwf,datasink,[('applywarp_mean.out_file','preproc.@mean')]),\n",
    "                 \n",
    "                (coregwf,art,[('applywarp.out_file','realigned_files')]),\n",
    "                (mcflirt,art,[('par_file','realignment_parameters')]),\n",
    "                 \n",
    "                (coregwf,datasink,[('coreg_bbr.out_matrix_file','preproc.@mat_file'),\n",
    "                                  ('bet_anat.out_file','preproc.@brain')]),\n",
    "                (art,datasink,[('outlier_files','preproc.@outlier_files'),\n",
    "                              ('plot_files','preproc.@plot_files')]),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc.base_dir,'preprocessing','graph.png'), width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproc.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "preproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize results tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /home/ubuntu/Documents/windowshare/output/XP2/datasink/preproc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outliers=np.zeros((len(subject_list),len(task_list),len(run_list)))\n",
    "                      \n",
    "for ii in range(len(subject_list)) :\n",
    "\n",
    "    for tt in range(len(task_list)) :   \n",
    "\n",
    "          for rr in range(len(run_list)) :\n",
    "                      out_dir='/home/ubuntu/Documents/windowshare/output/XP2/datasink/preproc/sub-%s/task-%s/run-%s' % (subject_list[ii],task_list[tt],run_list[rr])\n",
    "                      outliers_file='art.sub-%s_task-%s_run-%s_bold_outliers.txt' %(subject_list[ii],task_list[tt],run_list[rr])\n",
    "                      outliers = np.loadtxt(opj(out_dir,outliers_file))\n",
    "                      a=np.array(list(outliers.astype('int')))\n",
    "                      num_outliers[ii,tt,rr]=len(a[a<320])\n",
    "                     \n",
    "np.save(opj('/home/ubuntu/Documents/windowshare/output/XP2/datasink/preproc','array_outliers_task_%s.npy' %task_list[tt]),num_outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean+std number of outliers \n",
    "mean_out=num_outliers.mean()\n",
    "\n",
    "std_out=num_outliers.std()\n",
    "print(mean_out,std_out)\n",
    "print((mean_out*100)/320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
